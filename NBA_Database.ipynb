{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'book_name', 'book_id', 'team_id', 'a_team_id', 'spread1',\n",
      "       'spread2', 'price1', 'price2'],\n",
      "      dtype='object')\n",
      "game_id\n",
      "21000358    1\n",
      "20901228    1\n",
      "40900121    1\n",
      "40900131    1\n",
      "40900161    1\n",
      "           ..\n",
      "21700693    1\n",
      "21700694    1\n",
      "21700696    1\n",
      "21700698    1\n",
      "21501153    1\n",
      "Name: count, Length: 13789, dtype: int64\n",
      "     game_id  book_name  book_id     team_id   a_team_id  spread1  spread2  \\\n",
      "3   21000358  BetOnline     1096  1610612749  1610612742      7.5     -7.5   \n",
      "12  21000361  BetOnline     1096  1610612755  1610612751     -1.5      1.5   \n",
      "21  21000362  BetOnline     1096  1610612747  1610612764    -10.5     10.5   \n",
      "30  21000367  BetOnline     1096  1610612747  1610612754     -3.5      3.5   \n",
      "39  21000372  BetOnline     1096  1610612766  1610612763      8.5     -8.5   \n",
      "\n",
      "    price1  price2  \n",
      "3   -110.0  -110.0  \n",
      "12  -110.0  -110.0  \n",
      "21  -110.0  -110.0  \n",
      "30  -110.0  -110.0  \n",
      "39  -110.0  -110.0  \n",
      "(13789, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file (betting spreads)\n",
    "df = pd.read_csv(\"nba_data/nba_betting_spread.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n",
    "\n",
    "# Show all column names\n",
    "print(df.columns)\n",
    "\n",
    "# Filter for BetOnline\n",
    "df_betOnline = df[df['book_name'] == 'BetOnline']\n",
    "\n",
    "# Ensure only one entry per Game ID for BetOnline\n",
    "print(df_betOnline['game_id'].value_counts())\n",
    "\n",
    "# The Filter Dataset\n",
    "df_betOnline.to_csv('nba_data/nba_betting_spread_betOnline.csv', index=False)\n",
    "\n",
    "# Verify the Filtered Data\n",
    "print(df_betOnline.head())\n",
    "print(df_betOnline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnecessary columns removed, and dataset saved as nba_betting_spread_cleaned.csv!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"nba_data/nba_betting_spread_betOnline.csv\")\n",
    "\n",
    "# List of columns to drop (replace with actual columns you don't need)\n",
    "columns_to_drop2 = [\"book_name\", \"book_id\", \"price1\", \"price2\"]\n",
    "\n",
    "# Remove the unnecessary columns\n",
    "df_cleaned = df.drop(columns=columns_to_drop2)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv(\"nba_data/nba_betting_spread_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Unnecessary columns removed, and dataset saved as nba_betting_spread_cleaned.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with season 2006 removed saved as nba_games_filtered_season_2006_removed.csv!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"nba_data/nba_games_all.csv\")  # Use your preprocessed file\n",
    "\n",
    "# Filter out rows where season_year == 2006\n",
    "df_filtered = df[df[\"season_year\"] != 2006]\n",
    "\n",
    "# Save the cleaned dataset with a new name\n",
    "df_filtered.to_csv(\"nba_data/nba_games_all_filtered.csv\", index=False)\n",
    "\n",
    "print(\"Dataset with season 2006 removed saved as nba_games_filtered_season_2006_removed.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnecessary columns removed, and dataset saved as nba_games_final_cleaned.csv!\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"nba_data/nba_games_all_filtered.csv\")\n",
    "\n",
    "# List of columns to drop (replace with actual columns you don't need)\n",
    "columns_to_drop = [\"game_date\", \"matchup\", \"w\", \"l\", \"season_year\", \"min\", \"fgm\", \"fga\", \"fg_pct\", \"fg3m\", \"fg3a\", \"fg3_pct\", \"ftm\", \"fta\", \"ft_pct\", \"oreb\", \"dreb\", \"reb\", \"ast\", \"stl\", \"blk\", \"tov\", \"pf\", \"pts\", \"season\"]\n",
    "\n",
    "# Remove the unnecessary columns\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv(\"nba_data/nba_games_final.csv\", index=False)\n",
    "\n",
    "print(\"Unnecessary columns removed, and dataset saved as nba_games_final_cleaned.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset created! Saved as factors_and_spreads.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the core dataset\n",
    "games_df = pd.read_csv(\"nba_data/nba_games_final.csv\")\n",
    "\n",
    "# Load the betting spread dataset\n",
    "spreads_df = pd.read_csv(\"nba_data/nba_betting_spread_cleaned.csv\")\n",
    "\n",
    "# Merge the datasets on game_id\n",
    "merged_df = games_df.merge(spreads_df[[\"game_id\", \"spread1\", \"spread2\"]], on=\"game_id\", how=\"left\")\n",
    "\n",
    "# Save the final dataset\n",
    "merged_df.to_csv(\"nba_data/factors_and_spreads.csv\", index=False)\n",
    "\n",
    "print(\"Final dataset created! Saved as factors_and_spreads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as factors_and_spreads_filtered.csv! Only games with spread1 > 0 are kept and duplicates are removed.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")  # Your dataset\n",
    "\n",
    "# Filter the dataset to include only games where spread1 > 0 (i.e., favorites)\n",
    "df_favorites = df[df[\"spread1\"] > 0]\n",
    "\n",
    "# Drop duplicates based on game_id, keeping only the first occurrence\n",
    "df_favorites_unique = df_favorites.drop_duplicates(subset=[\"game_id\"], keep=\"first\")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_favorites_unique.to_csv(\"nba_data/factors_and_spreads.csv\", index=False)\n",
    "\n",
    "print(\"Filtered dataset saved as factors_and_spreads_filtered.csv! Only games with spread1 > 0 are kept and duplicates are removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing 'w_pct' have been removed and the dataset is saved.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Remove rows where 'w_pct' is NaN\n",
    "df_cleaned = df.dropna(subset=[\"w_pct\"])\n",
    "\n",
    "# Save the cleaned dataset back to CSV\n",
    "df_cleaned.to_csv(\"nba_data/factors_and_spreads.csv\", index=False)\n",
    "\n",
    "print(\"Rows with missing 'w_pct' have been removed and the dataset is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved as factors_and_spreads.csv with 'is_upset' column!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Create is_upset column: True if the team was an underdog and won, OR if the favorite lost\n",
    "df[\"is_upset\"] = ((df[\"spread1\"] > 0) & (df[\"wl\"] == \"W\"))\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"nba_data/factors_and_spreads.csv\", index=False)\n",
    "\n",
    "print(\"Updated dataset saved as factors_and_spreads.csv with 'is_upset' column!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preseason games removed. Dataset updated and saved!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Filter out Preseason games\n",
    "df = df[df[\"season_type\"] != \"Pre Season\"]\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(\"nba_data/factors_and_spreads.csv\", index=False)\n",
    "\n",
    "print(\"Preseason games removed. Dataset updated and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 count      mean       std  min    25%    50%    75%  max\n",
      "season_type                                                              \n",
      "Playoffs         720.0  0.515860  0.305558  0.0  0.333  0.571  0.685  1.0\n",
      "Regular Season  8504.0  0.498654  0.174712  0.0  0.375  0.500  0.617  1.0\n",
      "Fixed playoff w_pct! Saved updated dataset.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Check if Playoff games have different w_pct patterns\n",
    "print(df.groupby(\"season_type\")[\"w_pct\"].describe())  \n",
    "\n",
    "# Step 1: Calculate each team's regular-season win percentage\n",
    "regular_season_wpct = (\n",
    "    df[df[\"season_type\"] == \"Regular Season\"]\n",
    "    .groupby(\"team_id\")[\"w_pct\"]\n",
    "    .last()  # Get the last available w_pct (final reg season record)\n",
    ")\n",
    "\n",
    "# Step 2: Update Playoff games' w_pct to their team's regular-season w_pct\n",
    "df.loc[df[\"season_type\"] == \"Playoffs\", \"w_pct\"] = df[\"team_id\"].map(regular_season_wpct)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"nba_data/factors_and_spreads.csv\", index=False)\n",
    "\n",
    "print(\"Fixed playoff w_pct! Saved updated dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Upset Rate: 49.10%\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Check the overall percentage of upsets\n",
    "upset_rate = df[\"is_upset\"].mean()\n",
    "print(f\"Overall Upset Rate: {upset_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_home\n",
      "f    0.282035\n",
      "t    0.707910\n",
      "Name: is_upset, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "homecourt_upset_rate = df.groupby(\"is_home\")[\"is_upset\"].mean()\n",
    "print(homecourt_upset_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season_type\n",
      "Playoffs          0.475000\n",
      "Regular Season    0.492357\n",
      "Name: is_upset, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "season_type_upset_rate = df.groupby(\"season_type\")[\"is_upset\"].mean()\n",
    "print(season_type_upset_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f' 't']\n",
      "[False  True]\n",
      "         upsets  games      prop\n",
      "is_home                         \n",
      "False      1325   4698  0.282035\n",
      "True       3204   4526  0.707910\n",
      "An underdog team playing away won 28.2% of the time\n",
      "An underdog team playing at home won 70.8% of the time\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Check unique values in is_home\n",
    "print(df['is_home'].unique())\n",
    "\n",
    "# Map 't' to True, 'f' to False, and handle NaN values\n",
    "df['is_home'] = df['is_home'].map({'t': True, 'f': False})\n",
    "df['is_home'] = df['is_home'].fillna(False)  # If there are any NaN values, treat them as False\n",
    "\n",
    "# Verify that mapping worked\n",
    "print(df['is_home'].unique())  # Should return [True, False]\n",
    "\n",
    "# Group by 'is_home' and calculate upsets and games\n",
    "upset_summary = df.groupby('is_home').agg(\n",
    "    upsets=('is_upset', 'sum'),  # Count total upsets\n",
    "    games=('is_upset', 'count')  # Count total games\n",
    ")\n",
    "\n",
    "# Calculate proportion of upsets\n",
    "upset_summary['prop'] = upset_summary['upsets'] / upset_summary['games']\n",
    "\n",
    "# Print the summary table\n",
    "print(upset_summary)\n",
    "\n",
    "print('An underdog team playing away won 28.2% of the time')\n",
    "print('An underdog team playing at home won 70.8% of the time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           upsets  games      prop\n",
      "w_pct_bin                         \n",
      "Low           627   2345  0.267377\n",
      "Mid-Low      1024   2272  0.450704\n",
      "Mid-High     1289   2308  0.558492\n",
      "High         1589   2299  0.691170\n",
      "Teams with a win percentage in the bottom 25th percentile win as an underdog 26.7% of the time.\n",
      "Teams with a win percentage in the 25-50th percentile win as an underdog 45.1% of the time.\n",
      "Teams with a win percentage in the 50-75th percentile win as an underdog 55.8% of the time.\n",
      "Teams with a win percentage in the top 25th percentile win as an underdog 69.1% of the time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/0j9q5vjs2_l2pp_7wflhtr3w0000gn/T/ipykernel_58975/701655469.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  w_pct_upset_summary = df.groupby(\"w_pct_bin\").agg(\n"
     ]
    }
   ],
   "source": [
    "# Bin teams into four groups based on win percentage\n",
    "df[\"w_pct_bin\"] = pd.qcut(df[\"w_pct\"], q=4, labels=[\"Low\", \"Mid-Low\", \"Mid-High\", \"High\"])\n",
    "\n",
    "# Group by w_pct_bin and calculate upset rates\n",
    "w_pct_upset_summary = df.groupby(\"w_pct_bin\").agg(\n",
    "    upsets=(\"is_upset\", \"sum\"),  # Total upsets\n",
    "    games=(\"is_upset\", \"count\")  # Total games\n",
    ")\n",
    "\n",
    "# Compute upset proportion\n",
    "w_pct_upset_summary[\"prop\"] = w_pct_upset_summary[\"upsets\"] / w_pct_upset_summary[\"games\"]\n",
    "\n",
    "# Print the results\n",
    "print(w_pct_upset_summary)\n",
    "print('Teams with a win percentage in the bottom 25th percentile win as an underdog 26.7% of the time.')\n",
    "print('Teams with a win percentage in the 25-50th percentile win as an underdog 45.1% of the time.')\n",
    "print('Teams with a win percentage in the 50-75th percentile win as an underdog 55.8% of the time.')\n",
    "print('Teams with a win percentage in the top 25th percentile win as an underdog 69.1% of the time.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  home_w_pct_bin  upsets  games      prop\n",
      "0      Away High     297    705  0.421277\n",
      "1       Away Low     315   1728  0.182292\n",
      "2  Away Mid-High     331    986  0.335700\n",
      "3   Away Mid-Low     382   1279  0.298671\n",
      "4      Home High    1292   1594  0.810540\n",
      "5       Home Low     312    617  0.505673\n",
      "6  Home Mid-High     958   1322  0.724660\n",
      "7   Home Mid-Low     642    993  0.646526\n",
      "Away High: 42.13% upset rate\n",
      "Away Low: 18.23% upset rate\n",
      "Away Mid-High: 33.57% upset rate\n",
      "Away Mid-Low: 29.87% upset rate\n",
      "Home High: 81.05% upset rate\n",
      "Home Low: 50.57% upset rate\n",
      "Home Mid-High: 72.47% upset rate\n",
      "Home Mid-Low: 64.65% upset rate\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"nba_data/factors_and_spreads.csv\")\n",
    "\n",
    "# Step 1: Map 't' to True, 'f' to False, and handle NaN values for is_home\n",
    "df['is_home'] = df['is_home'].map({'t': True, 'f': False})\n",
    "df['is_home'] = df['is_home'].fillna(False)  # If there are any NaN values, treat them as False\n",
    "\n",
    "# Step 2: Bin teams into four groups based on win percentage\n",
    "df[\"w_pct_bin\"] = pd.qcut(df[\"w_pct\"], q=4, labels=[\"Low\", \"Mid-Low\", \"Mid-High\", \"High\"])\n",
    "\n",
    "# Step 3: Create a new column that combines 'is_home' and 'w_pct_bin' for easy grouping\n",
    "df['home_w_pct_bin'] = df['is_home'].map({True: 'Home', False: 'Away'}) + \" \" + df['w_pct_bin'].astype(str)\n",
    "\n",
    "# Step 4: Group by the new 'home_w_pct_bin' column and calculate upset statistics\n",
    "upset_summary = df.groupby('home_w_pct_bin').agg(\n",
    "    upsets=('is_upset', 'sum'),  # Total upsets\n",
    "    games=('is_upset', 'count')  # Total games\n",
    ")\n",
    "\n",
    "# Step 5: Compute upset proportion\n",
    "upset_summary['prop'] = upset_summary['upsets'] / upset_summary['games']\n",
    "\n",
    "# Step 6: Reset index for better readability\n",
    "upset_summary = upset_summary.reset_index()\n",
    "\n",
    "# Print the summary table\n",
    "print(upset_summary)\n",
    "\n",
    "# Interpret results\n",
    "for _, row in upset_summary.iterrows():\n",
    "    print(f\"{row['home_w_pct_bin']}: {row['prop']*100:.2f}% upset rate\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
